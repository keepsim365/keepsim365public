import os
import json
import csv
import logging
from datetime import datetime

# Configure logging
log_filename = f'process_log_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
logging.basicConfig(filename=log_filename, level=logging.INFO, format='%(asctime)s - %(message)s')

# Directory containing the JSON files
json_folder = r'C:\Users\g48430250\Desktop\code\0210 Connect Backup Data\0210 Connect Backup Data\users'  # Adjust your path here

# Output CSV file
output_csv = 'output_data.csv'

# Columns for the CSV
csv_columns = ['id', 'name', 'email']  # Modify based on the structure of your JSON files

def process_json_files():
    data_rows = []

    try:
        # Loop through all files in the folder
        for filename in os.listdir(json_folder):
            if filename.endswith('.json'):
                filepath = os.path.join(json_folder, filename)

                # Read each JSON file
                with open(filepath, 'r') as json_file:
                    try:
                        data = json.load(json_file)
                        print(f"Processing file: {filename}")  # Print filename for debugging
                        print(data)  # Print the content of the JSON file to verify its structure

                        if not data:
                            logging.warning(f'{filename} is empty or invalid JSON.')
                            continue

                        # Extract relevant fields (adjust as per your JSON structure)
                        row = {
                            'id': data.get('id', ''),
                            'name': data.get('name', ''),
                            'email': data.get('email', '')
                        }

                        # Check if required fields are missing and log a warning
                        if 'id' not in data or 'name' not in data or 'email' not in data:
                            logging.warning(f'Missing fields in {filename}: {data}')

                        data_rows.append(row)
                        logging.info(f'Successfully processed {filename}')
                    except json.JSONDecodeError as e:
                        logging.error(f'Error decoding JSON from {filename}: {e}')

        # Write to CSV
        with open(output_csv, 'w', newline='') as csv_file:
            writer = csv.DictWriter(csv_file, fieldnames=csv_columns)
            writer.writeheader()

            if data_rows:
                writer.writerows(data_rows)
                print(f"Data written to {output_csv}: {data_rows}")  # Debug print to check if rows are written
                logging.info(f'Successfully wrote data to {output_csv}')
            else:
                print("No data rows to write.")  # Debug print to see if data_rows is empty
                logging.warning('No data rows found to write to CSV.')
    except Exception as e:
        logging.error(f'Error processing files: {e}')

if __name__ == '__main__':
    process_json_files()
