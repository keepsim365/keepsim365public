import boto3
import csv
from datetime import datetime, timezone

# Initialize AWS service clients
lambda_client = boto3.client('lambda')
iam_client = boto3.client('iam')
ec2_client = boto3.client('ec2')
logs_client = boto3.client('logs')
sc_client = boto3.client('servicecatalog')

# Helper function to categorize age in months
def categorize_last_used(days_ago):
    if days_ago is None:
        return "No data"
    months = days_ago * 1.0 / 30.0
    if months <= 3:
        return "<=3 months"
    elif months <= 6:
        return "3-6 months"
    elif months <= 12:
        return "6-12 months"
    elif months <= 24:
        return "12-24 months"
    else:
        return ">24 months"

# 1. Audit Lambda Functions
lambda_fields = ["FunctionName", "CreationDate", "LastInvoked", "LastInvokedAgeDays", "UsageCategory", "Notes"]
with open("lambdas_report.csv", "w", newline='') as lf:
    writer = csv.writer(lf)
    writer.writerow(lambda_fields)
    # Paginate through all Lambda functions
    paginator = lambda_client.get_paginator('list_functions')
    for page in paginator.paginate():
        for func in page['Functions']:
            name = func['FunctionName']
            # Parse last modified time as creation (assuming no code updates after creation in Dev)
            creation_str = func.get('LastModified')  # e.g. "2023-05-01T12:34:56.000+0000"
            try:
                creation_date = datetime.strptime(creation_str, "%Y-%m-%dT%H:%M:%S.%f%z")
            except Exception:
                creation_date = None
            # Determine last invocation via CloudWatch Logs
            last_invoked = None
            last_invoked_age = None
            notes = ""
            log_group = f"/aws/lambda/{name}"
            try:
                streams = logs_client.describe_log_streams(
                    logGroupName=log_group,
                    orderBy='LastEventTime',
                    descending=True,
                    limit=1
                )
                if streams.get('logStreams'):
                    last_ts = streams['logStreams'][0].get('lastEventTimestamp')
                    if last_ts:
                        # lastEventTimestamp is in milliseconds
                        last_invoked = datetime.fromtimestamp(last_ts/1000.0, tz=timezone.utc)
                        last_invoked_age = (datetime.now(timezone.utc) - last_invoked).days
                else:
                    notes = "No log streams (never invoked?)"
            except logs_client.exceptions.ResourceNotFoundException:
                notes = "No log group (never invoked)"
            # Categorize usage
            usage_cat = categorize_last_used(last_invoked_age) if last_invoked_age is not None else "Never Invoked"
            # Write CSV row
            create_str = creation_date.strftime("%Y-%m-%d %H:%M:%S") if creation_date else "Unknown"
            last_invoked_str = last_invoked.strftime("%Y-%m-%d %H:%M:%S") if last_invoked else "None"
            writer.writerow([name, create_str, last_invoked_str, 
                             f"{last_invoked_age}" if last_invoked_age is not None else "N/A", 
                             usage_cat, notes])

# 2. Audit IAM Roles
role_fields = ["RoleName", "CreationDate", "LastUsedDate", "LastUsedAgeDays", "UsageCategory"]
with open("iam_roles_report.csv", "w", newline='') as rf:
    writer = csv.writer(rf)
    writer.writerow(role_fields)
    paginator = iam_client.get_paginator('list_roles')
    for page in paginator.paginate():
        for role in page['Roles']:
            name = role['RoleName']
            create_date = role['CreateDate']  # datetime object
            # Get last used info (may be None if never used or beyond tracking period)
            last_used_date = None
            if 'RoleLastUsed' in role and role['RoleLastUsed'].get('LastUsedDate'):
                last_used_date = role['RoleLastUsed']['LastUsedDate']
            # Calculate days since last use
            last_used_age = None
            if last_used_date:
                last_used_age = (datetime.now(timezone.utc) - last_used_date.replace(tzinfo=timezone.utc)).days
            # Determine category
            usage_cat = categorize_last_used(last_used_age) if last_used_age is not None else "Not used in 400+ days"
            writer.writerow([
                name,
                create_date.strftime("%Y-%m-%d"),
                last_used_date.strftime("%Y-%m-%d") if last_used_date else "None",
                f"{last_used_age}" if last_used_age is not None else "N/A",
                usage_cat
            ])

# 3. Audit ENIs (Network Interfaces)
eni_fields = ["ENI_ID", "Status", "AttachedResource", "CreationTime", "LastAttachTime", "Notes"]
with open("eni_report.csv", "w", newline='') as ef:
    writer = csv.writer(ef)
    writer.writerow(eni_fields)
    enis = ec2_client.describe_network_interfaces()['NetworkInterfaces']
    for eni in enis:
        eni_id = eni['NetworkInterfaceId']
        status = eni['Status']  # 'in-use' or 'available'
        attached_resource = "None"
        creation_time = eni.get('TagSet', [{}])  # default if no explicit creation time
        notes = ""
        attach_time = None
        if status == 'in-use':
            # Identify what it is attached to
            attachment = eni.get('Attachment', {})
            attach_time = attachment.get('AttachTime')
            if 'InstanceId' in attachment:
                attached_resource = f"EC2 Instance {attachment['InstanceId']}"
            elif 'InstanceOwnerId' in attachment:
                # Could be a lambda or other service; description might have the Lambda name or resource info
                attached_resource = attachment.get('InstanceOwnerId')
        else:
            # available (not attached)
            attach_time = eni.get('Attachment', {}).get('AttachTime')
            if not attach_time:
                # If never attached, use update time as creation marker (as a proxy)
                attach_time = eni.get('AvailabilityZone')  # (We may not have exact creation timestamp)
            notes = "Orphaned ENI (not attached)"
        create_str = attach_time.strftime("%Y-%m-%d %H:%M:%S") if isinstance(attach_time, datetime) else "Unknown"
        writer.writerow([eni_id, status, attached_resource, create_str, create_str, notes])

# 4. Audit Service Catalog products
sc_fields = ["ProductName", "ProductId", "CreatedTime", "OwnerPortfolio"]
with open("servicecatalog_products_report.csv", "w", newline='') as sf:
    writer = csv.writer(sf)
    writer.writerow(sc_fields)
    # Use paginator to list all products visible to admin
    paginator = sc_client.get_paginator('search_products_as_admin')
    for page in paginator.paginate(PageSize=20):
        for product_view in page.get('ProductViewDetails', []):
            product = product_view['ProductViewSummary']
            name = product['Name']
            product_id = product['ProductId']
            owner = product.get('Owner') or "Unknown"
            # Note: created time might not be directly in summary; could fetch via describe_product_as_admin if needed
            created_time = product_view.get('CreatedTime')
            created_str = created_time.strftime("%Y-%m-%d") if isinstance(created_time, datetime) else "Unknown"
            writer.writerow([name, product_id, created_str, owner])
